--- jemalloc.c.orig	2012-04-02 04:47:45.000000000 +0400
+++ jemalloc.c	2012-03-04 17:39:09.000000000 +0400
@@ -99,7 +99,7 @@
  * defaults the A and J runtime options to off.  These settings are appropriate
  * for production systems.
  */
-/* #define	MALLOC_PRODUCTION */
+#define	MALLOC_PRODUCTION
 
 #ifndef MALLOC_PRODUCTION
    /*
@@ -107,10 +107,10 @@
     * inline functions.
     */
 #  define MALLOC_DEBUG
+#endif
 
    /* MALLOC_STATS enables statistics calculation. */
-#  define MALLOC_STATS
-#endif
+#define MALLOC_STATS
 
 /*
  * MALLOC_BALANCE enables monitoring of arena lock contention and dynamically
@@ -125,43 +125,55 @@
  * unnecessary, but we are burdened by history and the lack of resource limits
  * for anonymous mapped memory.
  */
-#define	MALLOC_DSS
+/* #define	MALLOC_DSS */
 
 #include <sys/cdefs.h>
-__FBSDID("$FreeBSD: src/lib/libc/stdlib/malloc.c,v 1.172 2008/06/10 15:46:18 jasone Exp $");
 
-#include "libc_private.h"
+#ifndef __FBSDID
+#define __FBSDID(x)
+#endif
+
+__FBSDID("$FreeBSD: src/lib/libc/stdlib/malloc.c,v 1.171 2008/05/01 17:25:55 jasone Exp $");
+
 #ifdef MALLOC_DEBUG
 #  define _LOCK_DEBUG
 #endif
-#include "spinlock.h"
-#include "namespace.h"
 #include <sys/mman.h>
-#include <sys/param.h>
-#include <sys/stddef.h>
-#include <sys/time.h>
-#include <sys/types.h>
-#include <sys/sysctl.h>
+
+#ifndef MADV_FREE
+#define MADV_FREE MADV_DONTNEED
+#endif
+
 #include <sys/uio.h>
-#include <sys/ktrace.h> /* Must come after several other sys/ includes. */
 
-#include <machine/cpufunc.h>
-#include <machine/vmparam.h>
+#include <stddef.h>
+#include <sys/types.h>
 
 #include <errno.h>
 #include <limits.h>
+
+#ifndef SIZE_T_MAX
+#define SIZE_T_MAX SIZE_MAX
+#endif
+
 #include <pthread.h>
-#include <sched.h>
+
+#define __isthreaded (1)
+#define _pthread_mutex_trylock pthread_mutex_trylock
+#define _pthread_mutex_lock pthread_mutex_lock
+#define _pthread_mutex_unlock pthread_mutex_unlock
+#define _pthread_self pthread_self
+
 #include <stdarg.h>
 #include <stdbool.h>
 #include <stdio.h>
 #include <stdint.h>
 #include <stdlib.h>
 #include <string.h>
-#include <strings.h>
+#include <fcntl.h>
 #include <unistd.h>
-
-#include "un-namespace.h"
+#include <malloc.h>
+#include "malloc_arena.h"
 
 #ifdef MALLOC_DEBUG
 #  ifdef NDEBUG
@@ -176,6 +188,10 @@
 
 #include "rb.h"
 
+#define __unused
+#define __DECONST(type, val) ((type)(val))
+#define _getprogname() ("")
+
 #ifdef MALLOC_DEBUG
    /* Disable inlining to make debugging easier. */
 #  define inline
@@ -231,11 +247,6 @@
 #  define SIZEOF_INT_2POW	2
 #endif
 
-/* We can't use TLS in non-PIC programs, since TLS relies on loader magic. */
-#if (!defined(PIC) && !defined(NO_TLS))
-#  define NO_TLS
-#endif
-
 #ifdef NO_TLS
    /* MALLOC_BALANCE requires TLS. */
 #  ifdef MALLOC_BALANCE
@@ -349,14 +360,14 @@
  * issues in some cases.
  */
 typedef struct {
-	spinlock_t	lock;
+	pthread_spinlock_t	lock;
 } malloc_mutex_t;
 
 /* Set to true once the allocator has been initialized. */
 static bool malloc_initialized = false;
 
 /* Used to avoid initialization races. */
-static malloc_mutex_t init_lock = {_SPINLOCK_INITIALIZER};
+static pthread_mutex_t init_lock = PTHREAD_MUTEX_INITIALIZER;
 
 /******************************************************************************/
 /*
@@ -583,6 +594,8 @@
 	/* All operations on this arena require that lock be locked. */
 	pthread_mutex_t		lock;
 
+	struct arena_s *next; /* for private arenas */
+
 #ifdef MALLOC_STATS
 	arena_stats_t		stats;
 #endif
@@ -770,6 +783,9 @@
  */
 static arena_t		**arenas;
 static unsigned		narenas;
+static arena_t *arenas_priv;
+static arena_t **arenas_priv_last = &arenas_priv;
+
 #ifndef NO_TLS
 #  ifdef MALLOC_BALANCE
 static unsigned		narenas_2pow;
@@ -813,7 +829,6 @@
 #ifdef MALLOC_BALANCE
 static uint64_t	opt_balance_threshold = BALANCE_THRESHOLD_DEFAULT;
 #endif
-static bool	opt_print_stats = false;
 static size_t	opt_quantum_2pow = QUANTUM_2POW_MIN;
 static size_t	opt_small_max_2pow = SMALL_MAX_2POW_DEFAULT;
 static size_t	opt_chunk_2pow = CHUNK_2POW_DEFAULT;
@@ -829,6 +844,7 @@
 	void	*r;
 } malloc_utrace_t;
 
+#if 0
 #define	UTRACE(a, b, c)							\
 	if (opt_utrace) {						\
 		malloc_utrace_t ut;					\
@@ -837,6 +853,9 @@
 		ut.r = (c);						\
 		utrace(&ut, sizeof(ut));				\
 	}
+#else
+#define UTRACE(a, b, c) do { } while(0)
+#endif
 
 /******************************************************************************/
 /*
@@ -920,7 +939,6 @@
 static void	*huge_palloc(size_t alignment, size_t size);
 static void	*huge_ralloc(void *ptr, size_t size, size_t oldsize);
 static void	huge_dalloc(void *ptr);
-static void	malloc_print_stats(void);
 static bool	malloc_init_hard(void);
 
 /*
@@ -936,9 +954,7 @@
 static void
 malloc_mutex_init(malloc_mutex_t *mutex)
 {
-	static const spinlock_t lock = _SPINLOCK_INITIALIZER;
-
-	mutex->lock = lock;
+	pthread_spin_init(&mutex->lock, 0);
 }
 
 static inline void
@@ -946,7 +962,7 @@
 {
 
 	if (__isthreaded)
-		_SPINLOCK(&mutex->lock);
+		pthread_spin_lock(&mutex->lock);
 }
 
 static inline void
@@ -954,7 +970,7 @@
 {
 
 	if (__isthreaded)
-		_SPINUNLOCK(&mutex->lock);
+		pthread_spin_unlock(&mutex->lock);
 }
 
 /*
@@ -971,14 +987,9 @@
  * We use an unpublished interface to initialize pthread mutexes with an
  * allocation callback, in order to avoid infinite recursion.
  */
-int	_pthread_mutex_init_calloc_cb(pthread_mutex_t *mutex,
-    void *(calloc_cb)(size_t, size_t));
 
-__weak_reference(_pthread_mutex_init_calloc_cb_stub,
-    _pthread_mutex_init_calloc_cb);
-
-int
-_pthread_mutex_init_calloc_cb_stub(pthread_mutex_t *mutex,
+int __attribute__((weak))
+_pthread_mutex_init_calloc_cb(pthread_mutex_t *mutex,
     void *(calloc_cb)(size_t, size_t))
 {
 
@@ -1137,16 +1148,29 @@
 PRN_DEFINE(balance, balance_x, 1297, 1301)
 #endif
 
+#define _write(buf) if(buf && buf[0]) { \
+	iov[count] = (struct iovec) { (void *)buf, strlen(buf) }; \
+	++count; \
+}
+
 static void
 wrtmessage(const char *p1, const char *p2, const char *p3, const char *p4)
 {
+	struct iovec iov[4];
+	unsigned count = 0;
+	
+	_write(p1);
+	_write(p2);
+	_write(p3);
+	_write(p4);
 
-	_write(STDERR_FILENO, p1, strlen(p1));
-	_write(STDERR_FILENO, p2, strlen(p2));
-	_write(STDERR_FILENO, p3, strlen(p3));
-	_write(STDERR_FILENO, p4, strlen(p4));
+	if(count) {
+		size_t __attribute__((unused)) n = writev(STDERR_FILENO, iov, count);
+	}
 }
 
+#undef _write
+
 void	(*_malloc_message)(const char *p1, const char *p2, const char *p3,
 	    const char *p4) = wrtmessage;
 
@@ -1296,10 +1320,8 @@
 	malloc_mutex_lock(&base_mtx);
 	/* Make sure there's enough space for the allocation. */
 	if ((uintptr_t)base_next_addr + csize > (uintptr_t)base_past_addr) {
-		if (base_pages_alloc(csize)) {
-			malloc_mutex_unlock(&base_mtx);
+		if (base_pages_alloc(csize))
 			return (NULL);
-		}
 	}
 	/* Allocate. */
 	ret = base_next_addr;
@@ -1493,10 +1515,10 @@
 		 */
 		if (munmap(ret, size) == -1) {
 			char buf[STRERROR_BUF];
+			char const *errstr = strerror_r(errno, buf, sizeof(buf));
 
-			strerror_r(errno, buf, sizeof(buf));
 			_malloc_message(_getprogname(),
-			    ": (malloc) Error in munmap(): ", buf, "\n");
+			    ": (malloc) Error in munmap(): ", errstr, "\n");
 			if (opt_abort)
 				abort();
 		}
@@ -1514,10 +1536,10 @@
 
 	if (munmap(addr, size) == -1) {
 		char buf[STRERROR_BUF];
+		char const *errstr = strerror_r(errno, buf, sizeof(buf));
 
-		strerror_r(errno, buf, sizeof(buf));
 		_malloc_message(_getprogname(),
-		    ": (malloc) Error in munmap(): ", buf, "\n");
+		    ": (malloc) Error in munmap(): ", errstr, "\n");
 		if (opt_abort)
 			abort();
 	}
@@ -2686,12 +2708,10 @@
 	/* Initialize run internals. */
 	run->bin = bin;
 
-	for (i = 0; i < bin->regs_mask_nelms - 1; i++)
+	for (i = 0; i < bin->regs_mask_nelms; i++)
 		run->regs_mask[i] = UINT_MAX;
 	remainder = bin->nregs & ((1U << (SIZEOF_INT_2POW + 3)) - 1);
-	if (remainder == 0)
-		run->regs_mask[i] = UINT_MAX;
-	else {
+	if (remainder != 0) {
 		/* The last element has spare bits that need to be unset. */
 		run->regs_mask[i] = (UINT_MAX >> ((1U << (SIZEOF_INT_2POW + 3))
 		    - remainder));
@@ -3593,6 +3613,8 @@
 	if (malloc_spin_init(&arena->lock))
 		return (true);
 
+	arena->next = NULL;
+
 #ifdef MALLOC_STATS
 	memset(&arena->stats, 0, sizeof(arena_stats_t));
 #endif
@@ -3898,11 +3920,11 @@
 	base_node_dealloc(node);
 }
 
-static void
-malloc_print_stats(void)
+void
+malloc_stats(void)
 {
 
-	if (opt_print_stats) {
+	if (1) {
 		char s[UMAX2S_BUFSIZE];
 		_malloc_message("___ Begin malloc statistics ___\n", "", "",
 		    "");
@@ -3970,6 +3992,13 @@
 				}
 			}
 
+			for (arena = arenas_priv; arena; arena = arena->next) {
+				malloc_spin_lock(&arena->lock);
+				allocated += arena->stats.allocated_small;
+				allocated += arena->stats.allocated_large;
+				malloc_spin_unlock(&arena->lock);
+			}
+
 			/* huge/base. */
 			malloc_mutex_lock(&huge_mtx);
 			allocated += huge_allocated;
@@ -4021,6 +4050,16 @@
 					malloc_spin_unlock(&arena->lock);
 				}
 			}
+
+			for (arena = arenas_priv; arena; arena = arena->next) {
+				if (arena != NULL) {
+					malloc_printf(
+							"\narena(%x):\n", (arena_id_t)arena);
+					malloc_spin_lock(&arena->lock);
+					stats_print(arena);
+					malloc_spin_unlock(&arena->lock);
+				}
+			}
 		}
 #endif /* #ifdef MALLOC_STATS */
 		_malloc_message("--- End malloc statistics ---\n", "", "", "");
@@ -4042,37 +4081,67 @@
 	return (false);
 }
 
+static unsigned __cpu_number() {
+	char buf[8192];
+	unsigned res = 0;
+	enum { nl, c, p, u, none } state = nl;
+	char *ptr = buf;
+	char *ptr_e = buf;
+
+	int fd = open("/proc/stat", O_RDONLY);
+	if(fd < 0) return 1;
+
+	while(1) {
+		char ch;
+
+		if(ptr == ptr_e) {
+			ssize_t len = read(fd, buf, sizeof(buf));
+
+			if(len < 0) return 1;
+
+			if(!len)
+				break;
+
+			ptr_e = (ptr = buf) + len;
+		}
+
+		ch = *(ptr++);
+
+		switch(state) {
+			case nl: state = (ch == 'c') ? c : none; break;
+			case c: state = (ch == 'p') ? p : none; break;
+			case p: state = (ch == 'u') ? u : none; break;
+			case u: if(ch >= '0' && ch <= '9') ++res; state = none; break;
+			case none: if(ch == '\n') state = nl;
+		}
+	}
+
+	close(fd);
+
+	return res ?: 1;
+}
+
 static bool
 malloc_init_hard(void)
 {
 	unsigned i;
 	int linklen;
 	char buf[PATH_MAX + 1];
-	const char *opts;
+	const char *opts = NULL;
 
-	malloc_mutex_lock(&init_lock);
+	_pthread_mutex_lock(&init_lock);
 	if (malloc_initialized) {
 		/*
 		 * Another thread initialized the allocator before this one
 		 * acquired init_lock.
 		 */
-		malloc_mutex_unlock(&init_lock);
+		_pthread_mutex_unlock(&init_lock);
 		return (false);
 	}
 
 	/* Get number of CPUs. */
-	{
-		int mib[2];
-		size_t len;
 
-		mib[0] = CTL_HW;
-		mib[1] = HW_NCPU;
-		len = sizeof(ncpus);
-		if (sysctl(mib, 2, &ncpus, &len, (void *) 0, 0) == -1) {
-			/* Error. */
-			ncpus = 1;
-		}
-	}
+	ncpus = __cpu_number();
 
 	/* Get page size. */
 	{
@@ -4112,7 +4181,7 @@
 			}
 			break;
 		case 1:
-			if (issetugid() == 0 && (opts =
+			if ((opts =
 			    getenv("MALLOC_OPTIONS")) != NULL) {
 				/*
 				 * Do nothing; opts is already initialized to
@@ -4241,12 +4310,6 @@
 				case 'N':
 					opt_narenas_lshift++;
 					break;
-				case 'p':
-					opt_print_stats = false;
-					break;
-				case 'P':
-					opt_print_stats = true;
-					break;
 				case 'q':
 					if (opt_quantum_2pow > QUANTUM_2POW_MIN)
 						opt_quantum_2pow--;
@@ -4311,12 +4374,6 @@
 		opt_mmap = true;
 #endif
 
-	/* Take care to call atexit() only once. */
-	if (opt_print_stats) {
-		/* Print statistics at exit. */
-		atexit(malloc_print_stats);
-	}
-
 	/* Set variables according to the value of opt_small_max_2pow. */
 	if (opt_small_max_2pow < opt_quantum_2pow)
 		opt_small_max_2pow = opt_quantum_2pow;
@@ -4476,7 +4533,7 @@
 	/* Allocate and initialize arenas. */
 	arenas = (arena_t **)base_alloc(sizeof(arena_t *) * narenas);
 	if (arenas == NULL) {
-		malloc_mutex_unlock(&init_lock);
+		_pthread_mutex_unlock(&init_lock);
 		return (true);
 	}
 	/*
@@ -4491,7 +4548,7 @@
 	 */
 	arenas_extend(0);
 	if (arenas[0] == NULL) {
-		malloc_mutex_unlock(&init_lock);
+		_pthread_mutex_unlock(&init_lock);
 		return (true);
 	}
 #ifndef NO_TLS
@@ -4513,7 +4570,8 @@
 	malloc_spin_init(&arenas_lock);
 
 	malloc_initialized = true;
-	malloc_mutex_unlock(&init_lock);
+	_pthread_mutex_unlock(&init_lock);
+
 	return (false);
 }
 
@@ -4521,10 +4579,110 @@
  * End general internal functions.
  */
 /******************************************************************************/
+
+/*
+ * Begin alena malloc functions.
+ */
+
+arena_id_t
+arena_create(void)
+{
+	arena_t *arena;
+
+	malloc_spin_lock(&arenas_lock);
+
+	/* Allocate enough space for trailing bins. */
+	arena = (arena_t *)base_alloc(sizeof(arena_t)
+	    + (sizeof(arena_bin_t) * (ntbins + nqbins + nsbins - 1)));
+
+	if (arena != NULL) {
+ 		if(arena_new(arena) == false) {
+			*arenas_priv_last = arena;
+			arenas_priv_last = &arena->next;
+		}
+		else {
+			arena = NULL;
+		}
+	}
+
+	malloc_spin_unlock(&arenas_lock);
+
+	return (arena_id_t)(arena);
+}
+
+void *
+arena_alloc(arena_id_t id, size_t size)
+{
+	arena_t *arena = (arena_t *)id;
+
+	if (malloc_init())
+		return NULL;
+
+	if (!arena)
+		return NULL;
+
+	if (size == 0) {
+		if (opt_sysv == false)
+			size = 1;
+		else {
+			return NULL;
+		}
+	}
+
+	if (size <= arena_maxclass)
+		return (arena_malloc(arena, size, false));
+	else
+		return (huge_malloc(size, false));
+
+}
+
+void *
+arena_realloc(arena_id_t id, void *ptr, size_t size)
+{
+	arena_t *arena = (arena_t *)id;
+
+	if (!arena)
+		return NULL;
+
+	if (size == 0) {
+		if (opt_sysv == false)
+			size = 1;
+		else {
+			if (ptr != NULL)
+				idalloc(ptr);
+			return NULL;
+		}
+	}
+
+	if (ptr != NULL) {
+		assert(malloc_initialized);
+
+		return iralloc(ptr, size);
+	} else {
+		return arena_alloc(id, size);
+	}
+}
+
+void
+arena_free(arena_id_t id, void *ptr)
+{
+	if (ptr != NULL) {
+		assert(malloc_initialized);
+
+		idalloc(ptr);
+	}
+}
+
+/*
+ * End non-posix alena malloc functions.
+ */
+/******************************************************************************/
 /*
  * Begin malloc(3)-compatible functions.
  */
 
+#pragma GCC visibility push(default)
+
 void *
 malloc(size_t size)
 {
@@ -4607,6 +4765,121 @@
 }
 
 void *
+memalign(size_t alignment, size_t size)
+{
+	void *ret;
+
+	if (malloc_init())
+		ret = NULL;
+	else {
+		/* Make sure that alignment is a power of 2. */
+		if (((alignment - 1) & alignment) != 0) {
+			if (opt_xmalloc) {
+				_malloc_message(_getprogname(),
+				    ": (malloc) Error in memalign(): "
+				    "invalid alignment\n", "", "");
+				abort();
+			}
+			ret = NULL;
+			errno = EINVAL;
+			goto RETURN;
+		}
+
+		ret = ipalloc(alignment, size);
+	}
+
+	if (ret == NULL) {
+		if (opt_xmalloc) {
+			_malloc_message(_getprogname(),
+			": (malloc) Error in memalign(): out of memory\n",
+			"", "");
+			abort();
+		}
+		errno = ENOMEM;
+	}
+
+RETURN:
+	UTRACE(0, size, result);
+	return (ret);
+}
+
+void *
+valloc(size_t size)
+{
+	void *ret;
+
+	if (malloc_init()) {
+		ret = NULL;
+		goto RETURN;
+	}
+
+	if (size == 0) {
+		if (opt_sysv == false)
+			size = 1;
+		else {
+			ret = NULL;
+			goto RETURN;
+		}
+	}
+
+	ret = ipalloc(pagesize, size);
+
+RETURN:
+	if (ret == NULL) {
+		if (opt_xmalloc) {
+			_malloc_message(_getprogname(),
+			    ": (malloc) Error in valloc(): out of memory\n", "",
+			    "");
+			abort();
+		}
+		errno = ENOMEM;
+	}
+
+	UTRACE(0, size, ret);
+	return (ret);
+}
+
+void *
+pvalloc(size_t size)
+{
+	void *ret;
+	size_t real_size = 0;
+
+	if (malloc_init()) {
+		ret = NULL;
+		goto RETURN;
+	}
+
+	if (size == 0) {
+		if (opt_sysv == false)
+			real_size = pagesize;
+		else {
+			ret = NULL;
+			goto RETURN;
+		}
+	}
+	else {
+		real_size = PAGE_CEILING(size);
+	}
+
+	ret = ipalloc(pagesize, real_size);
+
+RETURN:
+	if (ret == NULL) {
+		if (opt_xmalloc) {
+			_malloc_message(_getprogname(),
+			    ": (malloc) Error in pvalloc(): out of memory\n", "",
+			    "");
+			abort();
+		}
+		errno = ENOMEM;
+	}
+
+	UTRACE(0, real_size, ret);
+	return (ret);
+}
+
+void *
 calloc(size_t num, size_t size)
 {
 	void *ret;
@@ -4728,7 +5001,7 @@
  */
 
 size_t
-malloc_usable_size(const void *ptr)
+malloc_usable_size(void *ptr)
 {
 
 	assert(ptr != NULL);
@@ -4751,6 +5024,7 @@
 _malloc_prefork(void)
 {
 	unsigned i;
+	arena_t *arena;
 
 	/* Acquire all mutexes in a safe order. */
 
@@ -4759,6 +5033,10 @@
 		if (arenas[i] != NULL)
 			malloc_spin_lock(&arenas[i]->lock);
 	}
+
+	for (arena = arenas_priv; arena; arena = arena->next)
+		malloc_spin_lock(&arena->lock);
+
 	malloc_spin_unlock(&arenas_lock);
 
 	malloc_mutex_lock(&base_mtx);
@@ -4774,6 +5052,7 @@
 _malloc_postfork(void)
 {
 	unsigned i;
+	arena_t *arena;
 
 	/* Release all mutexes, now that fork() has completed. */
 
@@ -4786,6 +5065,10 @@
 	malloc_mutex_unlock(&base_mtx);
 
 	malloc_spin_lock(&arenas_lock);
+
+	for (arena = arenas_priv; arena; arena = arena->next)
+		malloc_spin_unlock(&arena->lock);
+
 	for (i = 0; i < narenas; i++) {
 		if (arenas[i] != NULL)
 			malloc_spin_unlock(&arenas[i]->lock);
@@ -4797,3 +5080,69 @@
  * End library-private functions.
  */
 /******************************************************************************/
+
+void
+cfree(void* m)
+{
+	free(m);
+}
+
+int
+mallopt(int param_number, int value)
+{
+	return 1;
+}
+
+struct mallinfo
+mallinfo(void)
+{
+	struct mallinfo mi;
+	memset(&mi, 0, sizeof(mi));
+	return mi;
+}
+
+int
+malloc_trim(size_t pad)
+{
+	return 0;
+}
+
+void *
+malloc_get_state(void)
+{
+	return NULL;
+}
+
+int malloc_set_state(void *ptr)
+{
+	abort();
+}
+
+
+#define strong_alias(name, aliasname) \
+  extern __typeof (name) aliasname __attribute__ ((alias (#name)))
+
+strong_alias(calloc, __libc_calloc);
+strong_alias(free, __libc_free);
+strong_alias(cfree, __libc_cfree);
+strong_alias(malloc, __libc_malloc);
+strong_alias(memalign, __libc_memalign);
+strong_alias(realloc, __libc_realloc);
+strong_alias(valloc, __libc_valloc);
+strong_alias(pvalloc, __libc_pvalloc);
+strong_alias(mallopt, __libc_mallopt);
+strong_alias(mallinfo, __libc_mallinfo);
+
+void **
+__libc_independent_calloc(size_t n, size_t elem_size, void** chunks)
+{
+	abort();
+}
+
+void **
+__libc_independent_comalloc(size_t n, size_t sizes[], void** chunks)
+{
+	abort();
+}
+
+#pragma GCC visibility pop
